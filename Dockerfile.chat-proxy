FROM nvidia/cuda:12.8.0-runtime-ubuntu22.04

ENV PYTHONUNBUFFERED=1 \
    PIP_NO_CACHE_DIR=1 \
    PYTHONPATH=/app/src

WORKDIR /app

# Install Python and build prerequisites
RUN apt-get update && apt-get install -y --no-install-recommends \
        python3 \
        python3-pip \
        python3-venv \
        python3-dev \
        build-essential \
        git \
        ninja-build \
        pkg-config \
        ca-certificates \
        curl \
    && python3 -m pip install --upgrade pip \
    && rm -rf /var/lib/apt/lists/*

# Install runtime dependencies including vLLM GPU stack
RUN python3 -m pip install --no-cache-dir \
        "fastapi" \
        "uvicorn[standard]" \
        "httpx" \
        "pydantic" \
        "vllm[vision]==0.11.0" \
        "qwen-vl-utils"

# Copy required source and configs
COPY src/imageworks/chat_proxy /app/src/imageworks/chat_proxy
COPY src/imageworks/model_loader /app/src/imageworks/model_loader
COPY configs /app/configs

# Default env overrides for container usage
ENV CHAT_PROXY_HOST=0.0.0.0 \
    CHAT_PROXY_PORT=8100 \
    CHAT_PROXY_SUPPRESS_DECORATIONS=1 \
    CHAT_PROXY_INCLUDE_NON_INSTALLED=0

EXPOSE 8100

CMD ["python3", "-m", "imageworks.chat_proxy.app"]
