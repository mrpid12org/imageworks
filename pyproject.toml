[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "imageworks"
version = "0.1.0"
dependencies = [
  "typer",
  "numpy",
  "opencv-python-headless",
  "Pillow",
  "scikit-image",
  "scipy",
  "tomli; python_version < '3.11'",
  "tomli-w>=1.0.0",
  # Color-narrator VLM dependencies
  "torch>=2.3.0",
  "transformers>=4.57.1",
  "requests",
  "aiohttp",
  # Image metadata dependencies
  "exifread",
  "python-xmp-toolkit; sys_platform != 'win32'",
  # Additional utilities
  "tqdm",
  "rich",
  "vllm>=0.11.0",
  "lmdeploy>=0.10.1",
  "qwen-vl-utils>=0.0.14",
  "nvidia-ml-py>=13.580.82",
  # Model downloader dependencies
  "requests>=2.31.0",
  "aiohttp>=3.9.0",
  "safetensors>=0.4.5",
  "gguf>=0.9.1",
  "timm>=1.0.20",
  "fastapi>=0.111.0",
  "uvicorn>=0.30.0",
  # GUI dependencies
  "streamlit>=1.28.0",
  "streamlit-aggrid>=0.3.0",
  "plotly>=5.0.0",
  "markdown>=3.4.0",
  "psutil>=5.9.0",
  "watchdog>=3.0.0",
  "pandas>=2.0.0",
]
requires-python = ">=3.9"

[project.scripts]
imageworks-mono = "imageworks.apps.mono_checker.cli.mono:app"
imageworks-api = "imageworks.apps.mono_checker.api.main:start"
imageworks-zip = "imageworks.tools.zip_extract:app"
imageworks-color-narrator = "imageworks.apps.color_narrator.cli.main:app"
imageworks-personal-tagger = "imageworks.apps.personal_tagger.cli.main:app"
imageworks-image-similarity = "imageworks.apps.image_similarity_checker.cli.main:app"
imageworks-download = "imageworks.tools.model_downloader.cli:main"
imageworks-models = "imageworks.model_loader.cli:app"
imageworks-models-api = "imageworks.model_loader.api:app"
imageworks-loader = "imageworks.model_loader.cli_sync:app"
imageworks-gui = "imageworks.gui.app:main"
imageworks-chat-proxy = "imageworks.chat_proxy.app:main"


[tool.rye]
managed = true
dev-dependencies = [
    "ruff==0.5.4",
    "pytest==8.2.2",
    "black==24.4.2",
    "mypy==1.10.1",
    "pre-commit==3.7.1",
]

[tool.hatch.metadata]
allow-direct-references = true
[tool.hatch.build]
exclude = [".venv", ".pytest_cache", ".ruff_cache"]

[tool.hatch.build.targets.wheel]
packages = ["src/imageworks"]
include = [
  "src/imageworks/chat_templates/*.jinja",
]


[tool.ruff]
line-length = 88
indent-width = 4

[tool.ruff.lint]
select = ["E4", "E7", "E9", "F"]

[tool.imageworks.mono]
# Default folder to scan when none is provided on the command line.
# Can be an absolute path or relative to the project root.
default_folder = "/mnt/d/Proper Photos/photos/ccc competition images"

# Default file extensions to look for.
default_exts = "jpg,jpeg,png,tif,tiff"

# Default path for the JSONL output file.
default_jsonl = "outputs/results/mono_results.jsonl"

# Default path for the human-readable summary file.
default_summary = "outputs/summaries/mono_summary.md"

# --- CORE THRESHOLDS ---
# Max channel diff (0-255) for a pixel to be considered neutral.
neutral_tol = 2
# Max chroma (C*) for an image to pass as neutral.
lab_neutral_chroma = 2.0
# Chroma (C*) threshold above which pixels are considered "colored" for hue stats.
lab_chroma_mask = 2.0
# Max hue standard deviation (degrees) for a clear PASS as toned.
lab_toned_pass_deg = 10.0
# Max hue standard deviation (degrees) for a PASS WITH QUERY.
lab_toned_query_deg = 14.0

# --- HARD FAIL THRESHOLDS ---
# Force a FAIL if the percentage of pixels with chroma > 4 exceeds this.
lab_fail_c4_ratio = 0.10
# Force a FAIL if the largest single cluster of pixels with chroma > 4 exceeds this.
lab_fail_c4_cluster = 0.08


# --- HEATMAP VISUALIZATION DEFAULTS ---
# Default suffix for generated heatmap images.
default_visualize_suffix = "_mono_vis"
# Overlay opacity for heatmaps.
auto_heatmap_alpha = 0.6
# JPEG quality for heatmaps.
auto_heatmap_quality = 92
# Saturation threshold for saturation/hue heatmaps.
auto_heatmap_sat_threshold = 0.06
# Chroma (C*) value that maps to maximum intensity in LAB heatmaps.
lab_chroma_clip = 8.0

# --- XMP WRITING DEFAULTS ---
# Default name for the generated ExifTool script.
default_xmp_script = "write_xmp.sh"


[tool.imageworks.color_narrator]
# VLM server configuration
vlm_backend = "ollama"
vlm_base_url = "http://localhost:11434"
vlm_model = "qwen2.5vl:7b"
vlm_timeout = 120
vlm_max_tokens = 300
vlm_temperature = 0.1
vlm_vllm_base_url = "http://localhost:8000/v1"
vlm_vllm_model = "Qwen2-VL-2B-Instruct"
vlm_vllm_api_key = "EMPTY"
vlm_lmdeploy_base_url = "http://localhost:24001/v1"
vlm_lmdeploy_model = "Qwen2.5-VL-7B-AWQ"
vlm_lmdeploy_api_key = "EMPTY"
vlm_lmdeploy_eager = true
vlm_triton_base_url = "http://localhost:9000/v1"
vlm_triton_model = "Qwen2-VL-2B-Instruct"

# Processing configuration
default_batch_size = 4
min_contamination_level = 0.1
require_overlays = true
max_concurrent_requests = 4

# Data paths
default_images_dir = "/mnt/d/Proper Photos/photos/ccc competition images"
default_overlays_dir = "/mnt/d/Proper Photos/photos/ccc competition images"
default_mono_jsonl = "outputs/results/mono_results.jsonl"

# Output configuration


[tool.imageworks.zip-extract]
# Default source directory for ZIP files (WSL path)
default_zip_dir = "/mnt/c/Users/stewa/Downloads/CCC comp zips"
# Default extract root (WSL path for D:\\Proper Photos\\photos\\ccc competition images)
default_extract_root = "/mnt/d/Proper Photos/photos/ccc competition images"
backup_original_files = true
overwrite_existing_metadata = false
metadata_version = "1.0"

# Color analysis thresholds
chroma_threshold = 5.0
min_region_size = 100
high_chroma_threshold = 15.0

# Debug and development settings
debug_save_intermediate = false
debug_output_dir = "outputs/debug"
log_level = "INFO"

# Prompt templates
default_prompt_template = "color_narration"
validation_prompt_template = "color_validation"


[tool.imageworks.personal_tagger]
# Runtime defaults for the personal tagger CLI.
default_input_dirs = []
default_output_jsonl = "outputs/results/personal_tagger.jsonl"
default_summary_path = "outputs/summaries/personal_tagger_summary.md"
default_backend = "vllm"
default_model = "qwen3-vl-8b-instruct-abliterated_(FP8)"
default_base_url = "http://localhost:8100/v1"
default_timeout = 120
default_max_new_tokens = 512
default_temperature = 0.2
default_top_p = 0.9
default_prompt_profile = "club_judge_json"
default_batch_size = 2
default_max_workers = 2
default_recursive = false
default_dry_run = false
default_backup_originals = true
default_overwrite_metadata = false
default_use_registry = true
caption_model = "qwen3-vl-8b-instruct-abliterated_(FP8)"
keyword_model = "qwen3-vl-8b-instruct-abliterated_(FP8)"
description_model = "qwen3-vl-8b-instruct-abliterated_(FP8)"
default_api_key = "EMPTY"
max_keywords = 15
image_extensions = [
  ".jpg",
  ".jpeg",
  ".png",
  ".tif",
  ".tiff",
  ".orf",
  ".cr2",
  ".cr3",
]
json_schema_version = "1.0"


[tool.imageworks.image_similarity_checker]
default_library_root = "/mnt/d/Proper Photos/photos/ccc competition images"
default_output_jsonl = "outputs/results/similarity_results.jsonl"
default_summary_path = "outputs/summaries/similarity_summary.md"
default_cache_dir = "outputs/cache/similarity"
default_strategies = ["embedding", "perceptual_hash"]
default_fail_threshold = 0.92
default_query_threshold = 0.82
default_top_matches = 5
default_similarity_metric = "cosine"
default_embedding_backend = "siglip"
default_embedding_model = "google/siglip-base-patch16-224"
default_backend = "vllm"
default_model = "Qwen2.5-VL-7B-AWQ"
default_base_url = "http://localhost:8100/v1"  # Chat proxy with autostart & history management
default_write_metadata = false
default_backup_originals = true
default_overwrite_metadata = false
default_use_loader = false
default_generate_explanations = false
default_prompt_profile = "baseline"
image_extensions = [
  ".jpg",
  ".jpeg",
  ".png",
  ".tif",
  ".tiff",
]


[tool.imageworks.model-downloader]
# Model downloader configuration
linux_wsl_root = "~/ai-models"
windows_lmstudio_root = "/mnt/d/ai stuff/models/llm models"
max_connections_per_server = 16
max_concurrent_downloads = 8
enable_resume = true
include_optional_files = false
preferred_formats = ["awq", "safetensors", "gguf", "gptq"]

# Download timeout settings
timeout_seconds = 30
retry_attempts = 3
retry_delay_seconds = 5

# Registry and cache paths (relative to linux_wsl_root)
registry_subdir = "registry"
cache_subdir = "cache"

# =============================================================================
# Deployment Profiles - Auto-selected based on GPU hardware
# =============================================================================

[tool.imageworks.deployment_profiles.constrained_16gb]
description = "RTX 4080 16GB - single model, load/unload strategy"
max_vram_mb = 14000  # 16384 - 2048 headroom
max_concurrent_models = 1
preferred_quantizations = ["q4_k_m", "fp8", "awq", "q5_k_m", "q8_0"]
strategy = "load_unload"
autostart_timeout_seconds = 120
grace_period_seconds = 300
model_selection_bias = "vram_efficient"

[tool.imageworks.deployment_profiles.balanced_24gb]
description = "RTX 4090 24GB - dual model concurrent serving"
max_vram_mb = 22000  # 24576 - 2048 headroom
max_concurrent_models = 2
preferred_quantizations = ["fp8", "awq", "q4_k_m", "q5_k_m"]
strategy = "concurrent_limited"
autostart_timeout_seconds = 90
grace_period_seconds = 600
model_selection_bias = "balanced"

[tool.imageworks.deployment_profiles.multi_gpu_2x16gb]
description = "2x RTX 4080 16GB - tensor parallel or distributed models"
max_vram_mb = 28000  # (16384 * 2) - 4096 headroom
max_concurrent_models = 3
gpu_count = 2
preferred_quantizations = ["fp8", "awq", "bf16", "q5_k_m"]
strategy = "tensor_parallel_or_distributed"
autostart_timeout_seconds = 150
grace_period_seconds = 600
tensor_parallel_threshold_mb = 12000
model_selection_bias = "quality"

[tool.imageworks.deployment_profiles.generous_96gb]
description = "RTX 6000 Pro 96GB - multi-model concurrent serving"
max_vram_mb = 90000  # 98304 - 8192 headroom
max_concurrent_models = 5
preferred_quantizations = ["fp8", "awq", "bf16", "fp16"]
strategy = "concurrent_full"
autostart_timeout_seconds = 60
grace_period_seconds = 3600
model_selection_bias = "quality"

[tool.imageworks.deployment_profiles.development]
description = "Development/testing - minimal footprint"
max_vram_mb = 10000
max_concurrent_models = 1
preferred_quantizations = ["q4_k_m", "q5_k_m", "q8_0"]
strategy = "load_unload"
autostart_timeout_seconds = 180
grace_period_seconds = 120
model_selection_bias = "vram_efficient"

[dependency-groups]
dev = [
    "pytest>=8.4.2",
]
