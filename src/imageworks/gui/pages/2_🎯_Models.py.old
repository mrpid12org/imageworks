"""Models management hub page."""

import streamlit as st
from pathlib import Path
import json
import subprocess
from typing import Dict, List, Any, Optional
import time

from imageworks.gui.state import init_session_state
from imageworks.gui.components.registry_table import (
    render_registry_table,
    render_registry_stats,
)
from imageworks.gui.components.backend_monitor import (
    render_backend_monitor,
    render_system_resources,
)
from imageworks.gui.components.process_runner import execute_command
from imageworks.gui.utils.cli_wrapper import build_downloader_command
from imageworks.gui.config import MODEL_REGISTRY_PATH, DEFAULT_BACKENDS, PROJECT_ROOT
from imageworks.model_loader.registry import save_registry
from imageworks.model_loader.registry import load_registry as load_model_registry
from imageworks.model_loader.download_adapter import list_downloads


def run_command_with_progress(
    command: List[str],
    description: str,
    show_output: bool = True,
    timeout: Optional[int] = None,
) -> Dict[str, Any]:
    """Run command with progress indicator and optional output display."""
    with st.spinner(description):
        result = execute_command(command, timeout=timeout)

    if show_output:
        if result["success"]:
            st.success(f"‚úÖ {description} - Complete")
            if result["stdout"]:
                with st.expander("üìÑ Output", expanded=False):
                    st.code(result["stdout"])
        else:
            st.error(f"‚ùå {description} - Failed")
            if result["stderr"]:
                st.error(result["stderr"])

    return result


def confirm_destructive_operation(operation_name: str, details: str) -> bool:
    """Show confirmation dialog for destructive operations."""
    st.warning(f"‚ö†Ô∏è **{operation_name}**")
    st.markdown(details)

    confirm_key = f"confirm_{operation_name.replace(' ', '_').lower()}"
    confirmed = st.checkbox(
        f"I understand this will {operation_name.lower()}",
        key=confirm_key
    )

    return confirmed


def render_browse_manage_tab():
    """Browse & Manage tab - model browsing with role/config editing."""
    st.markdown("### üìö Browse & Manage Models")

    # Stats widget
    with st.expander("üìä Registry Statistics", expanded=True):
        render_registry_stats()

    st.markdown("---")

    # Model table with filters
    selected_model = render_registry_table(
        key_prefix="browse_manage",
        filterable_columns=["backend", "format", "quantization"]
    )

    if selected_model:
        st.markdown("---")
        st.markdown("### üîç Selected Model Details")

        col1, col2 = st.columns(2)

        with col1:
            st.write(f"**Name:** {selected_model.get('name', 'Unknown')}")
            st.write(f"**Backend:** {selected_model.get('backend', 'Unknown')}")
            st.write(f"**Format:** {selected_model.get('format', 'Unknown')}")
            st.write(f"**Quantization:** {selected_model.get('quantization', 'None')}")

        with col2:
            st.write(f"**Path:** {selected_model.get('path', 'Unknown')}")

            # Show size if available
            model_path = Path(selected_model.get("path", ""))
            if model_path.exists():
                if model_path.is_file():
                    size_mb = model_path.stat().st_size / (1024 * 1024)
                    st.write(f"**Size:** {size_mb:.1f} MB")
                elif model_path.is_dir():
                    total_size = sum(
                        f.stat().st_size
                        for f in model_path.rglob("*")
                        if f.is_file()
                    )
                    size_gb = total_size / (1024 * 1024 * 1024)
                    st.write(f"**Size:** {size_gb:.2f} GB")

        # Full metadata
        with st.expander("üìã Full Metadata", expanded=False):
            st.json(selected_model)

        # Role & Configuration Management
        st.markdown("---")
        st.markdown("### üé≠ Role & Configuration Management")

        model_name = selected_model.get('name', '')

        if model_name:
            registry = load_model_registry()
            registry_entry = registry.get(model_name)

            if registry_entry:
                # Role assignment
                st.markdown("#### Assigned Roles")

                available_roles = [
                    "caption",
                    "keywords",
                    "description",
                    "narration",
                    "vision_general",
                    "chat",
                    "code",
                    "reasoning",
                ]

                current_roles = list(registry_entry.roles or [])

                selected_roles = st.multiselect(
                    "Roles this model can perform",
                    options=available_roles,
                    default=current_roles,
                    key=f"roles_{model_name}",
                    help="Select all roles this model is capable of performing",
                )

                # Role Priority Editor
                if selected_roles:
                    st.markdown("#### Role Priority Scores")
                    st.caption("Higher priority = preferred for that role (0-100)")

                    role_priorities = {}
                    cols = st.columns(min(len(selected_roles), 3))

                    for idx, role in enumerate(selected_roles):
                        col_idx = idx % 3
                        with cols[col_idx]:
                            current_priority = registry_entry.role_priority.get(role, 50)
                            priority = st.number_input(
                                f"{role}",
                                min_value=0,
                                max_value=100,
                                value=current_priority,
                                step=5,
                                key=f"priority_{model_name}_{role}",
                            )
                            role_priorities[role] = priority

                # Backend Config Editor
                st.markdown("---")
                st.markdown("#### Backend Configuration")

                backend_config = registry_entry.backend_config

                col1, col2 = st.columns(2)

                with col1:
                    st.write(f"**Backend:** {registry_entry.backend}")
                    if backend_config:
                        st.write(f"**Port:** {backend_config.port}")
                    else:
                        st.write(f"**Port:** N/A")

                with col2:
                    if backend_config:
                        st.write(f"**Host:** {backend_config.host or 'localhost'}")
                    else:
                        st.write(f"**Host:** localhost")

                # Extra Args Editor
                st.markdown("**Extra Arguments**")
                st.caption("Additional CLI arguments passed to the backend (one per line)")

                current_extra_args = backend_config.extra_args if backend_config else []
                extra_args_text = "\n".join(current_extra_args)

                edited_extra_args = st.text_area(
                    "Extra Arguments (one per line)",
                    value=extra_args_text,
                    height=150,
                    key=f"extra_args_{model_name}",
                    help="Example args:\n--max-model-len 8192\n--gpu-memory-utilization 0.9\n--tensor-parallel-size 2",
                    label_visibility="collapsed",
                )

                # Common arg helpers
                with st.expander("üìñ Common Arguments", expanded=False):
                    st.markdown("""
                    **vLLM:**
                    - `--max-model-len 8192` - Set context length
                    - `--gpu-memory-utilization 0.9` - GPU memory fraction
                    - `--tensor-parallel-size 2` - Multi-GPU parallelism

                    **LMDeploy:**
                    - `--tp 2` - Tensor parallelism
                    - `--cache-max-entry-count 0.9` - KV cache size

                    **Ollama:**
                    - `--num-ctx 8192` - Context length
                    - `--num-gpu 1` - Number of GPU layers
                    """)

                # Save button
                st.markdown("---")
                col1, col2, col3 = st.columns([1, 1, 2])

                with col1:
                    if st.button("üíæ Save Changes", type="primary", key=f"save_{model_name}"):
                        try:
                            # Update registry entry
                            registry_entry.roles = selected_roles
                            registry_entry.role_priority = role_priorities

                            # Update extra_args in backend_config
                            new_extra_args = [
                                line.strip()
                                for line in edited_extra_args.split('\n')
                                if line.strip()
                            ]

                            if backend_config:
                                backend_config.extra_args = new_extra_args

                            # Save registry
                            save_registry()

                            st.success(f"‚úÖ Saved changes for {model_name}")
                            st.rerun()

                        except Exception as e:
                            st.error(f"‚ùå Failed to save: {e}")

                with col2:
                    if st.button("‚Ü©Ô∏è Reset", key=f"reset_{model_name}"):
                        st.rerun()

            else:
                st.warning(f"Model '{model_name}' not found in registry")
        else:
            st.info("‚ÑπÔ∏è Select a model from the table above to edit its roles and configuration")


def render_download_tab():

    """Render model download tab."""
    st.markdown("### Download Models from HuggingFace")

    col1, col2 = st.columns([2, 1])

    with col1:
        model_input = st.text_input(
            "Model URL or owner/repo",
            value="",
            key="download_model_input",
            help="Enter HuggingFace URL or owner/repo (e.g., Qwen/Qwen2.5-VL-7B-AWQ)",
        )

    with col2:
        # Format preferences
        formats = st.multiselect(
            "Preferred Formats",
            options=["GGUF", "AWQ", "GPTQ", "safetensors"],
            default=["AWQ", "GGUF"],
            key="download_formats",
        )

    # Location selection
    location = st.selectbox(
        "Download Location",
        options=["linux_wsl", "windows_lmstudio", "custom"],
        key="download_location",
        help="Predefined locations or custom path",
    )

    custom_path = ""
    if location == "custom":
        custom_path = st.text_input("Custom Path", value="", key="download_custom_path")

    # Additional options
    col1, col2 = st.columns(2)

    with col1:
        resume = st.checkbox(
            "Resume interrupted downloads", value=True, key="download_resume"
        )

    with col2:
        update_registry = st.checkbox(
            "Update registry", value=True, key="download_update_registry"
        )

    # Download button
    if st.button("üì• Download Model", type="primary", disabled=not model_input):
        config = {
            "model": model_input,
            "format": formats,
            "location": location if location != "custom" else None,
            "output_dir": custom_path if custom_path else None,
            "resume": resume,
            "update_registry": update_registry,
        }

        with st.spinner(f"Downloading {model_input}..."):
            command = build_downloader_command(config)
            result = execute_command(command, timeout=3600)  # 1 hour timeout

            if result["success"]:
                st.success(f"‚úÖ Successfully downloaded {model_input}")
                st.text(result["stdout"])
            else:
                st.error("‚ùå Download failed")
                st.text(result["stderr"])

    # Download history
    st.markdown("---")
    st.markdown("### Recent Downloads")

    # TODO: Implement download history tracking
    st.info("Download history coming soon")


def render_backends_tab():
    """Render backends monitoring tab."""
    st.markdown("### Backend Status")

    # Render backend monitor
    render_backend_monitor(backends=DEFAULT_BACKENDS, key_prefix="models_backends")

    # System resources
    st.markdown("---")
    render_system_resources()

    # Backend management (placeholder)
    st.markdown("---")
    st.markdown("### Backend Management")
    st.info("‚ÑπÔ∏è Start/stop controls coming in Phase 6")

    # Show commands for manual starting
    with st.expander("üìù Manual Start Commands", expanded=False):
        st.code(
            """
# Start vLLM
uv run vllm serve <model_name> --port 24001

# Start LMDeploy
uv run lmdeploy serve api <model_name> --port 24001

# Start Ollama
ollama serve

# Start Chat Proxy
uv run imageworks-chat-proxy
        """,
            language="bash",
        )


def render_profiles_tab():
    """Render deployment profiles tab."""
    st.markdown("### Deployment Profiles")

    st.info("‚ÑπÔ∏è Deployment profile visualization coming in Phase 6")

    # Show current pyproject.toml role assignments
    st.markdown("### Current Role Assignments")

    from imageworks.gui.config import PROJECT_ROOT

    pyproject_path = PROJECT_ROOT / "pyproject.toml"

    if pyproject_path.exists():
        try:
            try:
                import tomllib
            except ImportError:
                import tomli as tomllib  # type: ignore[import-not-found]

            with open(pyproject_path, "rb") as f:
                config = tomllib.load(f)

            # Look for imageworks configuration
            imageworks_config = config.get("tool", {}).get("imageworks", {})

            if imageworks_config:
                st.json(imageworks_config)
            else:
                st.warning("No ImageWorks configuration found in pyproject.toml")

        except Exception as e:
            st.error(f"Failed to load pyproject.toml: {e}")
    else:
        st.error("pyproject.toml not found")

    # Role assignment editor (placeholder)
    st.markdown("---")
    st.markdown("### Edit Role Assignments")
    st.info("‚ÑπÔ∏è Role assignment editor coming in Phase 6")


def main():
    """Models management hub page."""
    init_session_state()

    st.title("üéØ Models Management")
    st.markdown("Manage models, backends, and deployment profiles")

    # Tabs for different functions
    tabs = st.tabs(["üìö Registry", "üì• Download", "üîå Backends", "‚öôÔ∏è Profiles"])

    # === REGISTRY TAB ===
    with tabs[0]:
        st.markdown("### Model Registry")

        # Registry stats
        render_registry_stats()

        st.markdown("---")

        # Registry table with filters
        selected_model = render_registry_table(
            key_prefix="models_registry", filterable_columns=["format", "quantization"]
        )

        if selected_model:
            st.markdown("---")
            st.markdown("### Selected Model Details")

            col1, col2 = st.columns(2)

            with col1:
                st.write(f"**Name:** {selected_model.get('name', 'Unknown')}")
                st.write(f"**Format:** {selected_model.get('format', 'Unknown')}")
                st.write(
                    f"**Quantization:** {selected_model.get('quantization', 'None')}"
                )

            with col2:
                st.write(f"**Path:** {selected_model.get('path', 'Unknown')}")

                # Show size if available
                model_path = Path(selected_model.get("path", ""))
                if model_path.exists():
                    if model_path.is_file():
                        size_mb = model_path.stat().st_size / (1024 * 1024)
                        st.write(f"**Size:** {size_mb:.1f} MB")
                    elif model_path.is_dir():
                        total_size = sum(
                            f.stat().st_size
                            for f in model_path.rglob("*")
                            if f.is_file()
                        )
                        size_mb = total_size / (1024 * 1024)
                        st.write(f"**Size:** {size_mb:.1f} MB")

            # Full metadata
            with st.expander("Full Metadata", expanded=False):
                st.json(selected_model)

            # Role Management Section
            st.markdown("---")
            st.markdown("### üé≠ Role & Configuration Management")

            # Get model name for registry lookup
            model_name = selected_model.get('name', '')

            if model_name:
                # Load current registry from model_loader
                registry = load_model_registry()
                registry_entry = registry.get(model_name)

                if registry_entry:
                    # Role assignment
                    st.markdown("#### Assigned Roles")

                    available_roles = [
                        "caption",
                        "keywords",
                        "description",
                        "narration",
                        "vision_general",
                        "chat",
                        "code",
                        "reasoning",
                    ]

                    current_roles = list(registry_entry.roles or [])

                    selected_roles = st.multiselect(
                        "Roles this model can perform",
                        options=available_roles,
                        default=current_roles,
                        key=f"roles_{model_name}",
                        help="Select all roles this model is capable of performing",
                    )

                    # Role Priority Editor
                    if selected_roles:
                        st.markdown("#### Role Priority Scores")
                        st.caption("Higher priority = preferred for that role (0-100)")

                        role_priorities = {}
                        cols = st.columns(min(len(selected_roles), 3))

                        for idx, role in enumerate(selected_roles):
                            col_idx = idx % 3
                            with cols[col_idx]:
                                current_priority = registry_entry.role_priority.get(role, 50)
                                priority = st.number_input(
                                    f"{role}",
                                    min_value=0,
                                    max_value=100,
                                    value=current_priority,
                                    step=5,
                                    key=f"priority_{model_name}_{role}",
                                )
                                role_priorities[role] = priority

                    # Backend Config Editor
                    st.markdown("---")
                    st.markdown("#### Backend Configuration")

                    backend_config = registry_entry.backend_config

                    col1, col2 = st.columns(2)

                    with col1:
                        st.write(f"**Backend:** {registry_entry.backend}")
                        if backend_config:
                            st.write(f"**Port:** {backend_config.port}")
                        else:
                            st.write(f"**Port:** N/A")

                    with col2:
                        if backend_config:
                            st.write(f"**Host:** {backend_config.host or 'localhost'}")
                        else:
                            st.write(f"**Host:** localhost")

                    # Extra Args Editor
                    st.markdown("**Extra Arguments**")
                    st.caption("Additional CLI arguments passed to the backend (one per line)")

                    current_extra_args = backend_config.extra_args if backend_config else []
                    extra_args_text = "\n".join(current_extra_args)

                    edited_extra_args = st.text_area(
                        "Extra Arguments (one per line)",
                        value=extra_args_text,
                        height=150,
                        key=f"extra_args_{model_name}",
                        help="Example args:\n--max-model-len 8192\n--gpu-memory-utilization 0.9\n--tensor-parallel-size 2",
                        label_visibility="collapsed",
                    )

                    # Common arg helpers
                    with st.expander("üìñ Common Arguments", expanded=False):
                        st.markdown("""
                        **vLLM:**
                        - `--max-model-len 8192` - Set context length
                        - `--gpu-memory-utilization 0.9` - GPU memory fraction
                        - `--tensor-parallel-size 2` - Multi-GPU parallelism

                        **LMDeploy:**
                        - `--tp 2` - Tensor parallelism
                        - `--cache-max-entry-count 0.9` - KV cache size

                        **Ollama:**
                        - `--num-ctx 8192` - Context length
                        - `--num-gpu 1` - Number of GPU layers
                        """)

                    # Save button
                    st.markdown("---")
                    col1, col2, col3 = st.columns([1, 1, 2])

                    with col1:
                        if st.button("üíæ Save Changes", type="primary", key=f"save_{model_name}"):
                            try:
                                # Update registry entry
                                registry_entry.roles = selected_roles
                                registry_entry.role_priority = role_priorities

                                # Update extra_args in backend_config
                                new_extra_args = [
                                    line.strip()
                                    for line in edited_extra_args.split('\n')
                                    if line.strip()
                                ]

                                if backend_config:
                                    # BackendConfig is a dataclass, update the extra_args field
                                    backend_config.extra_args = new_extra_args

                                # Save registry
                                save_registry()

                                st.success(f"‚úÖ Saved changes for {model_name}")
                                st.rerun()
                                st.rerun()

                            except Exception as e:
                                st.error(f"‚ùå Failed to save: {e}")

                    with col2:
                        if st.button("‚Ü©Ô∏è Reset", key=f"reset_{model_name}"):
                            st.rerun()

                else:
                    st.warning(f"Model '{model_name}' not found in registry")
            else:
                st.info("Select a model from the table above to edit its roles and configuration")

        # Registry management
        st.markdown("---")
        st.markdown("### Registry Management")

        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("üîÑ Refresh Registry"):
                from imageworks.gui.components.registry_table import load_registry

                load_registry.clear()
                st.rerun()

        with col2:
            if st.button("üìù Edit Registry"):
                st.info("Open registry file in editor")
                st.code(str(MODEL_REGISTRY_PATH))

        with col3:
            if st.button("üîó Sync from Downloader"):
                st.info("Sync command: uv run imageworks-download sync")

    # === DOWNLOAD TAB ===
    with tabs[1]:
        render_download_tab()

    # === BACKENDS TAB ===
    with tabs[2]:
        render_backends_tab()

    # === PROFILES TAB ===
    with tabs[3]:
        render_profiles_tab()


if __name__ == "__main__":
    main()
